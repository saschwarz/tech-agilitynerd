<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>tech.agilitynerd - nginx</title><link href="https://tech.agilitynerd.com/" rel="alternate"></link><link href="http://127.0.0.1:8000/feeds/tag.nginx.atom.xml" rel="self"></link><id>https://tech.agilitynerd.com/</id><updated>2016-09-23T18:00:00-05:00</updated><entry><title>HTTP/2: A Quick and Easy Website Speed Up</title><link href="https://tech.agilitynerd.com/http2-a-quick-and-easy-website-speed-up.html" rel="alternate"></link><published>2016-09-23T18:00:00-05:00</published><updated>2016-09-23T18:00:00-05:00</updated><author><name>Steve Schwarz</name></author><id>tag:tech.agilitynerd.com,2016-09-23:/http2-a-quick-and-easy-website-speed-up.html</id><summary type="html">&lt;p&gt;I always want my websites to be secure and fast. &lt;a class="reference external" href="https://http2.github.io/"&gt;HTTP/2&lt;/a&gt; is the latest enhancement to the HTTP protocol that can provide significant performance improvements:&lt;/p&gt;
&lt;blockquote class="epigraph"&gt;
&lt;p&gt;The primary goals for HTTP/2 are to reduce latency by enabling full request and response multiplexing, minimize protocol overhead via efficient compression of …&lt;/p&gt;&lt;/blockquote&gt;</summary><content type="html">&lt;p&gt;I always want my websites to be secure and fast. &lt;a class="reference external" href="https://http2.github.io/"&gt;HTTP/2&lt;/a&gt; is the latest enhancement to the HTTP protocol that can provide significant performance improvements:&lt;/p&gt;
&lt;blockquote class="epigraph"&gt;
&lt;p&gt;The primary goals for HTTP/2 are to reduce latency by enabling full request and response multiplexing, minimize protocol overhead via efficient compression of HTTP header fields, and add support for request prioritization and server push.&lt;/p&gt;
&lt;p class="attribution"&gt;&amp;mdash;&lt;a class="reference external" href="https://hpbn.co/http2/"&gt;High Performance Browser Networking - O'Reilly&lt;/a&gt;:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It turns out all browsers that support HTTP/2 &lt;a class="reference external" href="http://caniuse.com/#feat=http2"&gt;also require TLS (HTTPS)&lt;/a&gt;. So my first step was &lt;a class="reference external" href="https://tech.agilitynerd.com/nginx-https-lets-encrypt-and-django.html"&gt;adding HTTPS support to agilitycourses.com&lt;/a&gt; which also provides a backbone on which I'll implement secure user profiles. Then I wanted to enable HTTP/2 to see if it improved the speed of pages served to end users.&lt;/p&gt;
&lt;div class="section" id="but-first-an-os-upgrade"&gt;
&lt;h2&gt;But First an OS Upgrade&lt;/h2&gt;
&lt;p&gt;After a little research I found that recent releases of &lt;a class="reference external" href="https://nginx.org/en/"&gt;NGINX&lt;/a&gt; support HTTP/2 and those versions are packaged with Ubuntu 16.04 LTS. That made upgrading to this latest long term support OS version a better approach than just upgrading NGINX on my older OS. I basically went through the &lt;a class="reference external" href="https://www.digitalocean.com/community/tutorials/how-to-upgrade-to-ubuntu-16-04-lts"&gt;standard upgrade process&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;While I had to work through a number of small issues upgrading my older websites; the biggest change was converting my upstart scripts to systemd scripts. But the beauty of hosting with virtual servers is it was trivial to create an image of my existing server, spin up a temporary server using that image, and then practice the ugprade/migration on the temporary server. I was able to move some configuration changes back to my live server and test out the changes to my sites' &lt;a class="reference external" href="http://www.fabfile.org/"&gt;Fabric&lt;/a&gt; deployment scripts.&lt;/p&gt;
&lt;p&gt;Once everything was working I configured my websites that contain user modifiable data into maintenance mode on my temporary server. Then I pointed the DNS for all my domains to the temporary server. After DNS propagated I shutdown Postgres and the webserver on my original server and created a backup image. Then I went through the upgrade process. Once I validated the migration was successful I switched the DNS back to my original server and shutdown the temporary server. After a couple days I deleted the temporary server and the pre-migration backup image.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="enabling-http-2"&gt;
&lt;h2&gt;Enabling HTTP/2&lt;/h2&gt;
&lt;p&gt;Once I was on NGINX version 1.10 the change to the website to enable HTTP/2 was as simple as changing the virtual server from:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
server {
    listen 443 ssl;
    listen [::]:443 ssl;
...
}
&lt;/pre&gt;
&lt;p&gt;to:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
server {
    listen 443 ssl http2;
    listen [::]:443 ssl http2;
...
}
&lt;/pre&gt;
&lt;p&gt;Then I just reloaded the Nginx configuration: &lt;tt class="docutils literal"&gt;sudo systemctl reload nginx&lt;/tt&gt;. That was it!&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="testing"&gt;
&lt;h2&gt;Testing&lt;/h2&gt;
&lt;p&gt;Here's the network view of the timing of requests for a page using HTTP/1.1 over HTTPS in Chrome:&lt;/p&gt;
&lt;img alt="Diagram of HTTP requests for a page showing requests being delayed by previous requests for the same domain." class="thumbnail" src="/images/agilitycourses-http1.png" /&gt;
&lt;p&gt;Here's the same page using HTTP/2 over HTTPS:&lt;/p&gt;
&lt;img alt="Diagram of HTTP requests for a page showing requests being multiplexed with previous requests for the same domain." class="thumbnail" src="/images/agilitycourses-http2.png" /&gt;
&lt;p&gt;The obvious difference is in the &lt;em&gt;Timeline - Start Time&lt;/em&gt; column. In the first diagram you can see the &amp;quot;waterfall&amp;quot; queueing up of requests for images as all the open sockets to the domain were in use. In the second diagram you can see them all interleaved as they are multiplexed across the same connection.&lt;/p&gt;
&lt;p&gt;Also the bottom line is the page is fully loaded in 1.73 sec using HTTP/1.1 and in 1.16 sec using HTTP/2 for a &lt;strong&gt;33% end user page load improvement!&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="next-steps"&gt;
&lt;h2&gt;Next Steps&lt;/h2&gt;
&lt;p&gt;So that was a nice free speed up and there are plenty of areas I can still investigate to further improve the performance of this web site:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Bring 3rd party resources back to my domain to save DNS lookups and see how that affects overall performance. This may hurt performance for HTTP/1.1 clients who are limited to the number of connections per domain.&lt;/li&gt;
&lt;li&gt;Change multiple SVG files (which are all steps in a progression) into a single file and use CSS to hide/show appropriate steps using a single image. This will greatly reduce the number of individual files downloaded and save some duplicated data within those files.&lt;/li&gt;
&lt;li&gt;Move Google Analytics locally. GA has a number of problems (short cache times and multiple files downloaded) so at the cost of periodically updating the files I could host them all locally and save some time.&lt;/li&gt;
&lt;li&gt;Disqus is even worse than GA when it comes to many file downloads, redirects, short cache times etc. I might change to have Disqus data loaded on user demand.&lt;/li&gt;
&lt;li&gt;&lt;dl class="first docutils"&gt;
&lt;dt&gt;Experiment with other HTTP/2 features:&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.igvita.com/2015/08/17/eliminating-roundtrips-with-preconnect/"&gt;preconnect&lt;/a&gt; might help reduce the cost of DNS look ups that result from redirects like those used by Google Analytics, Google Fonts, and Disqus resources.&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://www.smashingmagazine.com/2016/02/preload-what-is-it-good-for/"&gt;preload&lt;/a&gt; to load resources before they are accessed by JS during &lt;tt class="docutils literal"&gt;onload&lt;/tt&gt; or via user actions.&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Link_prefetching_FAQ"&gt;prefetch&lt;/a&gt; to load JS/images for future pages. There are some common workflows on this site that could benefit from prefetching the JS for subsequent pages.&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</content><category term="nginx"></category><category term="ubuntu"></category><category term="https"></category><category term="ssl"></category><category term="http2"></category><category term="performance"></category></entry><entry><title>NGINX, HTTPS, Let's Encrypt, and Django</title><link href="https://tech.agilitynerd.com/nginx-https-lets-encrypt-and-django.html" rel="alternate"></link><published>2016-09-04T12:02:00-05:00</published><updated>2016-09-04T12:02:00-05:00</updated><author><name>Steve Schwarz</name></author><id>tag:tech.agilitynerd.com,2016-09-04:/nginx-https-lets-encrypt-and-django.html</id><summary type="html">&lt;p&gt;My &lt;a class="reference external" href="https://agilitycourses.com"&gt;agilitycourses.com&lt;/a&gt; website is served by &lt;a class="reference external" href="https://nginx.org/en/"&gt;nginx&lt;/a&gt; proxying to &lt;a class="reference external" href="http://gunicorn.org/"&gt;gunicorn&lt;/a&gt; running my &lt;a class="reference external" href="https://www.djangoproject.com/"&gt;Django&lt;/a&gt; application. I'll be adding user accounts soon so I wanted to convert the site to be more secure by using HTTPS encryption. Also &lt;a class="reference external" href="https://webmasters.googleblog.com/2014/08/https-as-ranking-signal.html"&gt;Google has announced it will likely prefer sites using HTTPS&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The site is …&lt;/p&gt;</summary><content type="html">&lt;p&gt;My &lt;a class="reference external" href="https://agilitycourses.com"&gt;agilitycourses.com&lt;/a&gt; website is served by &lt;a class="reference external" href="https://nginx.org/en/"&gt;nginx&lt;/a&gt; proxying to &lt;a class="reference external" href="http://gunicorn.org/"&gt;gunicorn&lt;/a&gt; running my &lt;a class="reference external" href="https://www.djangoproject.com/"&gt;Django&lt;/a&gt; application. I'll be adding user accounts soon so I wanted to convert the site to be more secure by using HTTPS encryption. Also &lt;a class="reference external" href="https://webmasters.googleblog.com/2014/08/https-as-ranking-signal.html"&gt;Google has announced it will likely prefer sites using HTTPS&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The site is running on Ubuntu 14.04 LTS. I won't recount the whole process, I followed some great resources and I'll discuss a couple adjustments that might be helpful to others.&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;I basically followed the instructions in this excellent Digital Ocean tutorial: &lt;a class="reference external" href="https://www.digitalocean.com/community/tutorials/how-to-secure-nginx-with-let-s-encrypt-on-ubuntu-14-04"&gt;How To Secure Nginx with Let's Encrypt on Ubuntu 14.04&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;I confirmed via the &lt;a class="reference external" href="https://www.ssllabs.com/ssltest/analyze.html"&gt;SSL Labs SSL Server Test&lt;/a&gt; that my IPv4 and IPv6 server configurations had &amp;quot;A+&amp;quot; ratings.&lt;/li&gt;
&lt;li&gt;While looking for other SSL testing sites I came across &lt;a class="reference external" href="https://securityheaders.io/"&gt;securityheaders.io&lt;/a&gt; developed by &lt;a class="reference external" href="https://scotthelme.co.uk/"&gt;Scott Helme&lt;/a&gt;. My initial score was a sad &amp;quot;D&amp;quot;. The site has snippets for NGINX and Apache configuration changes and in depth articles describing the how and the why.&lt;/li&gt;
&lt;li&gt;While investigating the changes to the HTTP Headers to improve my test score I came across this &lt;a class="reference external" href="https://github.com/jonnybarnes/nginx-conf"&gt;nginx-conf GitHub repository&lt;/a&gt;. Specifically the idea of putting the header settings into an &lt;a class="reference external" href="https://github.com/jonnybarnes/nginx-conf/blob/master/conf/includes/security-headers.conf"&gt;NGINX include file&lt;/a&gt;. I have several other domains on the same server and will also be converting them. I used that idea to include ssl and header configurations into any virtual host.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Here's my &lt;cite&gt;/etc/nginx/ssl.conf&lt;/cite&gt; file:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# From https://www.digitalocean.com/community/tutorials/how-to-secure-nginx-with-let-s-encrypt-on-ubuntu-14-04
ssl_protocols TLSv1 TLSv1.1 TLSv1.2;
ssl_prefer_server_ciphers on;
ssl_dhparam /etc/ssl/certs/dhparam.pem;
ssl_ciphers 'ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:kEDH+AESGCM:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA256:DHE-RSA-AES256-SHA256:DHE-DSS-AES256-SHA:DHE-RSA-AES256-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:AES:CAMELLIA:DES-CBC3-SHA:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!MD5:!PSK:!aECDH:!EDH-DSS-DES-CBC3-SHA:!EDH-RSA-DES-CBC3-SHA:!KRB5-DES-CBC3-SHA';
ssl_session_timeout 1d;
ssl_session_cache shared:SSL:50m;
ssl_stapling on;
ssl_stapling_verify on;
&lt;/pre&gt;
&lt;p&gt;And my &lt;cite&gt;/etc/nginx/security_headers.conf&lt;/cite&gt; file:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# See https://github.com/jonnybarnes/nginx-conf/blob/master/conf/includes/security-headers.conf
add_header X-Xss-Protection &amp;quot;1; mode=block&amp;quot;;
add_header X-Content-Type-Options &amp;quot;nosniff&amp;quot;;
add_header Content-Security-Policy &amp;quot;default-src https: data: 'unsafe-inline' 'unsafe-eval'&amp;quot;;
add_header Strict-Transport-Security max-age=15768000;
&lt;/pre&gt;
&lt;p&gt;So my server blocks with all these edits are now:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# redirect http://www.tld and http://tld to https://www.tld
server {
    listen 80;
    listen [::]:80;
    server_name www.agilitycourses.com agilitycourses.com;

    # letsencrypt location
    location ^~ /.well-known/ {
        allow all;
        root /usr/share/nginx/html/;
    }
    location / {
        return 301 https://www.agilitycourses.com$request_uri;
    }
}

# redirect https://tld to https://www.tld
server {
    listen 443 ssl;
    listen [::]:443 ipv6only=on ssl;

    server_name agilitycourses.com;
    # certificates are needed here too
    ssl_certificate /etc/letsencrypt/live/agilitycourses.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/agilitycourses.com/privkey.pem;
    return 301 https://www.agilitycourses.com$request_uri;
}

server {
    listen 443 ssl;
    listen [::]:443 ssl;

    server_name www.agilitycourses.com;
    root /home/agilitycourses/production/current/;

    ssl_certificate /etc/letsencrypt/live/agilitycourses.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/agilitycourses.com/privkey.pem;

    include /etc/nginx/ssl.conf;
    include /etc/nginx/security_headers.conf;
    ...
}
&lt;/pre&gt;
&lt;p&gt;So now I have an &amp;quot;A&amp;quot; score from &lt;cite&gt;securityheaders.io&lt;/cite&gt;&lt;/p&gt;
&lt;ol class="arabic" start="5"&gt;
&lt;li&gt;&lt;p class="first"&gt;The Digital Ocean tutorial sets up a root crontab entry to automatically update the SSL Certificate. I decided to also update the letsencrypt client software automatically:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# m h  dom mon dow   command
20 2 * * 1 cd /opt/letsencrypt &amp;amp;&amp;amp; git pull
30 2 * * 1 /opt/letsencrypt/letsencrypt-auto renew &amp;gt;&amp;gt; /var/log/le-renew.log
35 2 * * 1 /etc/init.d/nginx reload
&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;The last change I made was to pass along the presence/absence of HTTPS from NGINX to Gunicorn/Django via the &lt;cite&gt;X-Forwarded-Proto&lt;/cite&gt; header as &lt;a class="reference external" href="https://docs.djangoproject.com/en/1.10/topics/security/#ssl-https"&gt;described in the Django SSL/HTTPS docs&lt;/a&gt;&lt;/p&gt;
&lt;pre class="literal-block"&gt;
location &amp;#64;proxy-to-app {
    proxy_pass http://agilitycourses-production-gunicorn;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header Host $host;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    proxy_set_header Accept-Encoding &amp;quot;&amp;quot;;
    proxy_read_timeout 120;
    proxy_send_timeout 120;
    ...
}
&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p class="first"&gt;Based on the Django recommendations I also made these changes in my &lt;cite&gt;settings.py&lt;/cite&gt;:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
# SSL settings
SECURE_PROXY_SSL_HEADER = ('HTTP_X_FORWARDED_PROTO', 'https')
SECURE_BROWSER_XSS_FILTER = True
SESSION_COOKIE_SECURE = True
CSRF_COOKIE_SECURE = True
&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Even with a lot of web browsing to learn about these settings the whole process only took a couple hours.
Now that I've done it once (and updated my &lt;a class="reference external" href="http://www.fabfile.org/"&gt;Fabric fabfile.py&lt;/a&gt;) it will be easier to convert my other domains.&lt;/p&gt;
</content><category term="nginx"></category><category term="ubuntu"></category><category term="https"></category><category term="ssl"></category><category term="django"></category><category term="gunicorn"></category><category term="letsencrypt"></category></entry><entry><title>NGINX CGI Parameter Gotcha</title><link href="https://tech.agilitynerd.com/nginx-cgi-parameter-gotcha.html" rel="alternate"></link><published>2016-07-31T12:02:00-05:00</published><updated>2016-07-31T12:02:00-05:00</updated><author><name>Steve Schwarz</name></author><id>tag:tech.agilitynerd.com,2016-07-31:/nginx-cgi-parameter-gotcha.html</id><summary type="html">&lt;p&gt;When I first started the &lt;a class="reference external" href="http://agilitynerd.com"&gt;agilitynerd&lt;/a&gt;  blog in 2004 I had my &lt;a class="reference external" href="http://blosxom.sourceforge.net/"&gt;Blosxom&lt;/a&gt; blogging CGI script running via &lt;a class="reference external" href="http://httpd.apache.org/"&gt;Apache&lt;/a&gt;. Later on I moved all my sites to &lt;a class="reference external" href="https://nginx.org/en/"&gt;nginx&lt;/a&gt; or took advantage of nginx's caching features to have it act as a proxy in front of Apache. I finally decided to …&lt;/p&gt;</summary><content type="html">&lt;p&gt;When I first started the &lt;a class="reference external" href="http://agilitynerd.com"&gt;agilitynerd&lt;/a&gt;  blog in 2004 I had my &lt;a class="reference external" href="http://blosxom.sourceforge.net/"&gt;Blosxom&lt;/a&gt; blogging CGI script running via &lt;a class="reference external" href="http://httpd.apache.org/"&gt;Apache&lt;/a&gt;. Later on I moved all my sites to &lt;a class="reference external" href="https://nginx.org/en/"&gt;nginx&lt;/a&gt; or took advantage of nginx's caching features to have it act as a proxy in front of Apache. I finally decided to remove Apache entirely and that meant solving running CGI scripts using nginx.&lt;/p&gt;
&lt;p&gt;After some googling I found FastCGI and &lt;a class="reference external" href="https://www.nginx.com/resources/wiki/start/topics/examples/fcgiwrap/"&gt;fcgiwrap&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I'm on Ubuntu so installation was as easy as:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
sudo apt-get install fcgiwrap
&lt;/pre&gt;
&lt;p&gt;That setup the init script that starts the fcgi daemon. To run the cgi script(s) nginx has to be configured to parse apart the incoming URL, execute the appropriate script and pass along any arguments needed by the CGI script. Sounds easy.&lt;/p&gt;
&lt;p&gt;I only want to support running a single CGI script: &lt;tt class="docutils literal"&gt;index.cgi&lt;/tt&gt; and pass along the path after the root of URL as the argument to the script. Most examples are more generic and parse out any cgi script and any arguments.&lt;/p&gt;
&lt;p&gt;The key built-in to nginx to do the splitting is &lt;tt class="docutils literal"&gt;fastcgi_split_path_info&lt;/tt&gt; which takes a regex with two captured groups to parse out the script name and the arguments. These are stored in the &lt;tt class="docutils literal"&gt;$fastcgi_script_name&lt;/tt&gt; and the &lt;tt class="docutils literal"&gt;$fastcgi_path_info&lt;/tt&gt; variables respectively. This &lt;a class="reference external" href="https://www.digitalocean.com/community/tutorials/understanding-and-implementing-fastcgi-proxying-in-nginx"&gt;Digital Ocean article&lt;/a&gt; discusses FastCGI and has an excellent discussion of the variables available and also used by &lt;tt class="docutils literal"&gt;fcgiwrap&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;So I created this configuration file that matches &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;http://agilitynerd.com/blog/foo.html&lt;/span&gt;&lt;/tt&gt; and invokes &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;/home/agilitynerd/cgi-bin/index.cgi&lt;/span&gt; foo.html&lt;/tt&gt;:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
location /blog/ {
    root /home/agilitynerd/cgi-bin/;

    fastcgi_split_path_info ^(/blog)(.*)$;
    include /etc/nginx/fastcgi_params;
    fastcgi_param DOCUMENT_ROOT /home/agilitynerd/cgi-bin/;
    fastcgi_param SCRIPT_NAME index.cgi$fastcgi_path_info;

    # Fastcgi socket
    fastcgi_pass  unix:/var/run/fcgiwrap.socket;
}
&lt;/pre&gt;
&lt;p&gt;You'll notice: &lt;tt class="docutils literal"&gt;include /etc/nginx/fastcgi_params&lt;/tt&gt; is used to get default values for the &lt;tt class="docutils literal"&gt;fastcgi_param&lt;/tt&gt; variables.&lt;/p&gt;
&lt;p&gt;And it didn't work. I kept getting errors:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Cannot get script name, are DOCUMENT_ROOT and SCRIPT_NAME (or SCRIPT_FILENAME) set and is the script executable?&amp;quot;
&lt;/pre&gt;
&lt;p&gt;Clearly I'm setting &lt;tt class="docutils literal"&gt;DOCUMENT_ROOT&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;SCRIPT_NAME&lt;/tt&gt;. After almost a day of googling and testing (during which I found this helpful article on &lt;a class="reference external" href="https://blog.martinfjordvald.com/2013/06/debugging-nginx-errors/"&gt;nginx debugging&lt;/a&gt;) I temporarily commented out &lt;tt class="docutils literal"&gt;fastcgi_pass&lt;/tt&gt;, and returned the variables.&lt;/p&gt;
&lt;p&gt;I found that they were being set as I expected... Strange!&lt;/p&gt;
&lt;p&gt;Then I came across this &lt;a class="reference external" href="https://www.digitalocean.com/community/tutorials/understanding-and-implementing-fastcgi-proxying-in-nginx"&gt;Digital Ocean article&lt;/a&gt; where they have a critical discussion on overriding variables in which they state:&lt;/p&gt;
&lt;blockquote&gt;
This inconsistency and unpredictability means that you cannot and should not rely on the backend to correctly interpret your intentions when setting the same parameter more than one time. The only safe solution is to only declare each parameter once. This also means that there is no such thing as safely overriding a default value with the fastcgi_param directive.&lt;/blockquote&gt;
&lt;p&gt;So in my case I commented out &lt;tt class="docutils literal"&gt;DOCUMENT_ROOT&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;SCRIPT_FILENAME&lt;/tt&gt; in the &lt;tt class="docutils literal"&gt;/etc/nginx/fastcgi_params&lt;/tt&gt; file, reloaded nginx, and voila! Everything worked. Hope this helps you if you run in to the same problem.&lt;/p&gt;
</content><category term="nginx"></category><category term="cgi"></category><category term="fcgiwrap"></category><category term="ubuntu"></category><category term="apache"></category></entry></feed>